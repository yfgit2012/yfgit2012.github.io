## Hinton Nobel Prize speech

Here is the translation:

Sinton discussed the concept of Boltzmann Machine and Restricted Boltzmann Machine (RBM) in his lecture. He emphasized the limitations of the Boltzmann machine learning algorithm, particularly when dealing with complex images and large datasets.

To address this issue, he introduced a variant called Restricted Boltzmann Machine (RBM). This type of network has restricted connections between neurons, only allowing visible units and hidden units to connect with each other, but not between themselves.

Sinton mentioned the shortcut learning algorithm that can significantly simplify calculations and improve learning speed. This algorithm adjusts the weights between neurons by comparing original training images and new generated visible unit activations until the network can generate increasingly realistic images.

He also mentioned a method of stacking multiple RBMs to build a deep neural network. By doing so, it is possible to learn very complex feature representations and achieve good results. In actual applications, this type of deep neural network has been successful in image recognition and speech recognition fields.

Sinton believes that these early learning algorithms, although not the most perfect solutions, laid the foundation for the development of later more advanced algorithms and techniques. He is optimistic about exploring "sleeping" or unlearning methods to find a more biologically plausible algorithm that avoids backpropagation's reverse paths and ultimately provides new ways to understand how the brain learns.

#### Translation 

辛顿在他的演讲中讨论了玻尔兹曼机（Boltzmann Machine）和受限玻尔兹曼机（Restricted Boltzmann Machine, RBM）的概念。他强调了玻尔兹曼机学习算法的局限性，特别是在处理复杂图像和大规模数据时。为了解决这个问题，他介绍了一种称为受限玻尔兹曼机（RBM）的变体。这类网络的神经元连接是受限的，只允许可见单元和隐藏单元之间有连接，而没有相互之间的连接。

辛顿提到了捷径学习算法，它能够大大简化计算过程并提高学习速度。这种算法通过比较原始训练图像和新生成的可见单元激活模式来调整神经元之间的连接权重，直到网络能够生成越来越逼真的图像。

辛顿还提到了堆叠多个RBM来构建一个深度神经网络的方法。通过这种方式，可以学习到非常复杂的特征表示并取得很好的效果。在实际应用中，这种深度神经网络已经在图像识别、语音识别等领域取得了成功。

辛顿认为这些早期的学习算法虽然可能不是最完美的解决方案，但它们为后来更先进的算法和技术的发展奠定了基础。他乐观地抱着“睡眠”进行去学习（unlearning）的方法，以期能够找到一种更具备生物学合理性的算法，并且避免反向传播的逆向路径，最终为我们理解人脑如何学习提供新的途径。