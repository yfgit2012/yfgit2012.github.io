## Paper page - MinMo: A Multimodal Large Language Model for Seamless Voice Interaction

Here is the summary of the contents in no more than 50% of the total content length:

MinMo: A Multimodal Large Language Model for Seamless Voice Interaction
Published on Jan 10
·

Authors:
Qian Chen,
Yafeng Chen,
Yanni Chen,
Mengzhe Chen,
Yingda Chen,
Chong Deng,
Zhihao Du,
Ruize Gao,
Changfeng Gao,
Zhifu Gao,
Yabin Li,
Xiang Lv,
Jiaqing Liu,
Haoneng Luo,
Bin Ma,
Chongjia Ni,
Xian Shi,
Jialong Tang,
Hui Wang,
Hao Wang,
Wen Wang,
Yuxuan Wang

Abstract:
We introduce MinMo, a Multimodal Large Language Model with approximately 8B parameters for seamless voice interaction. We address the main limitations of prior aligned multimodal models by training MinMo through multiple stages of speech-to-text alignment, text-to-speech alignment, speech-to-speech alignment, and duplex interaction alignment on 1.4 million hours of diverse speech data.

MinMo achieves state-of-the-art performance across various benchmarks for voice comprehension and generation while maintaining the capabilities of text LLMs, and also facilitates full-duplex conversation. The enhanced instruction-following capabilities of MinMo supports controlling speech generation based on user instructions, with various nuances including emotions, dialects, and speaking rates, and mimicking specific voices.

#### Translation 

<document>
MinMo：一种全模态大型语言模型，用于无缝语音交互
出版日期：2023年1月10日

作者：
谭钦、
叶峰陈，
严宜，
孟哲陈，
营达陈，
崇烽邓，
知濠杜，
睿泽高.,
长风高.,
志福高,
翼斌李,
向良吕,
嘉青刘,
浩能罗,
彬马,
崇加倪,
先世曙,
佳龙唐,
慧王,
豪王,
文旺,

摘要：
我们介绍了MinMo，全模态大型语言模型，约8亿参数，为语音交互提供无缝体验。我们通过对1.4万小时多样化语音数据进行多阶段语音-文字、文字-语音、语音-语音和双向交互对齐来解决了前沿全模态模型的主要局限性。

MinMo在声学理解和生成方面实现了最好的性能，同时保持了文本LLM的能力，并且支持完整的双向会话。MinMo的增强指导执行能力，支持基于用户指令控制语音生成，包括情绪、方言、发音速率等细微差别，以及模仿特定声音。
</document>

#### Reference: 

https://huggingface.co/papers/2501.06282