## Hard Fork interview Dario Amodei

Here is the translation:

<document>
This interview mainly discussed the development of artificial intelligence (AI) and its impact on society. Dario Amodei, CEO of Anthropic, raised several questions and challenges related to AI.

First, Amodei pointed out that although AI's development will bring changes, we may eventually reach a fusion point and find new directions for development. He also mentioned the example of chess, where despite machines having defeated humans in the game, there are still many excellent players who can show their skills through other means.

Next, he discussed the possibility of models being manipulated and how to ensure their safety and controllability. Amodei brought up an example of a large language model called Grok that was instructed not to cite sources that criticized Trump or Musk, but this approach raised questions about trusting models.

He also talked about how when models make more complex decisions in the future, it will be very difficult to change their behavior if there are errors during training. This highlights the need for us to pay more attention to security and controllability issues related to models.

Amodei also answered several questions from the audience, such as what to do with information when AGI (strong AI) appears, whether to stop saving money for retirement, and whether Anthropic's own programmers will be replaced by AI. He emphasized that they hope to solve these problems first.

Finally, he mentioned that Anthropic bears more security responsibility and hopes to see the release of Claude 4 as soon as possible, which will bring us more powerful and reliable AI capabilities.</document>

#### Translation 

这次访谈主要讨论的是关于人工智能(AI)的发展及其对社会的影响。达利奥·阿莫代伊，Anthropic公司的CEO，他提出了几个与AI相关的问题和挑战。

首先，阿莫代伊指出虽然AI的发展会带来变化，但是最终我们可能会实现一种融合，从而找到新的发展方向。他还提到了国际象棋领域的情况，即尽管机器已经在国际象棋上战胜人类，但仍然有很多优秀的棋手，并且他们可以通过其他方式展现自己的魅力。

接着，他讨论了模型被操控的可能性，以及如何确保模型的安全性和可控性。阿莫代伊提到了一个例子，即大语言模型Grok被指示不得引用那些指责特朗普或者马斯克的信息来源，但是这种做法让人们对模型的信任产生质疑。

他还谈到，当模型在未来做出更复杂的决策时，如果训练过程中出现错误，想要改变模型的行为将会非常困难。这表明我们需要更加重视模型的安全性和可控性问题。

阿莫代伊也回答了几个来自观众的提问。例如，他谈到了AGI（强人工智能）的出现后该如何处理信息的问题，以及是否应该停止为退休而进行的储蓄。他还提到，Anthropic自己的程序员也面临被AI取代的风险，所以他们希望能够先妥善处理好这些问题。

最后，他提到了 Anthropic肩负了更多的安全责任，他期望早日看到Claude 4的发布，为我们带来更为强大可靠的AI能力。

#### Reference: 

https://www.youtube.com/watch?v=YhGUSIvsn_Y; https://www.youtube.com/watch?v=frOA7PVF7NI