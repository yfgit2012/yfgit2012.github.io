## Dispider: Enabling Video LLMs with Active Real-Time Interaction via Disentangled Perception, Decision, and Reaction

Here is the content within the <document> XML tags, summarized to no more than 50% of the total contents length:

Dispider: Enabling Video LLMs with Active Real-Time Interaction via
Disentangled Perception, Decision, and Reaction


Authors:
Rui Qian,
Shuangrui Ding,
Xiaoyi Dong,
Pan Zhang,
Yuhang Zang,
Yuhang Cao,
Dahua Lin,
Jiaqi Wang

Abstract
Active Real-time interaction with video LLMs introduces a new paradigm for human-computer interaction, where the model not only understands user intent but also responds while continuously processing streaming video on the fly.

Dispider features a lightweight proactive streaming video processing module that tracks the video stream and identifies optimal moments for interaction. Once the interaction is triggered, an asynchronous interaction module provides detailed responses, while the processing module continues to monitor the video in the meantime.

Experiments show that Dispider not only maintains strong performance in conventional video QA tasks but also significantly surpasses previous online models in streaming scenario responses. The code and model are released at https://github.com/Mark12Ding/Dispider.

#### Translation 

<document>视频LLMs的激活实时互动：通过分离感知、决策和反应

作者：
钱睿，
丁爽瑞，
董晓艺，
张磊，
张宇航，
曹宇航，
林达华，
王佳琦

综述
激活式实时互动视频LLMs引入了一个新的人机交互范式，模型不仅理解用户意图，而且能够在连续处理流媒体视频的同时回应。

Dispider具有轻量级的主动流媒体视频处理模块，可以监控视频流并识别最佳互动时刻。一旦触发互动，一个异步交互模块提供详细响应，而处理模块继续监控视频。

实验结果表明，Dispider不仅在传统视频QA任务中保持强性能，而且在流媒体场景响应方面大大超过了之前的在线模型。代码和模型已发布在https://github.com/Mark12Ding/Dispider上。</document>

#### Reference: 

https://huggingface.co/papers/2501.03218