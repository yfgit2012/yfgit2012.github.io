## Yann LeCun: LLM can never reach AGI

Here is the translation:

<document>
This article discusses the development trend of artificial intelligence, particularly Yang Lichun's speech content in 2023. The concepts mentioned in the speech include:

1. **World Model**: Yang Lichun emphasizes that the human brain solves complex problems through layered planning rather than reacting at a low level. This suggests that using a world model can bring many benefits to artificial intelligence, but how do we train a world model?

2. **Joint Embedding Prediction Architecture (JEPA)**: Yang Lichun mentioned his Joint Embedding Prediction Architecture (JEPA), which is based on the idea of giving up pixel-level predictions and letting models learn abstract representations of how the world works. Then training AI to predict future states based on these representations.

3. **The Essence of Science**: Yang Lichun calls this process the essence of science, finding a good version of some phenomenon, allowing the model to plan and predict when encountering bad situations, and returning to the good version.

4. **Information Quantization**: To stably train the Joint Embedding Prediction Architecture (JEPA), Yang Lichun mentioned information quantization, then measuring the information content from the encoder.

5. **Meta's Open-Source Philosophy**: Yang Lichun also mentioned that Meta thinks open-source artificial intelligence is not only a good idea but also necessary for preserving cultural diversity and democracy, and the availability of open-source AI models is one reason why the AI startup ecosystem is developing.

This article summarizes the content of Yang Lichun's speech in 2023, which has important reference value for understanding the current direction of artificial intelligence research.</document>

#### Translation 

这篇文章讨论了人工智能领域的发展趋势，特别是杨立昆在2023年的演讲内容。演讲中提到的人工智能概念包括：

1. **世界模型**： Yang立昆强调，人脑通过分层规划来处理复杂问题，而不是以低级别的方式做出反应。这表明使用世界模型可以为人工智能带来许多好处，但要如何训练一个世界模型呢？

2. **联合嵌入预测架构（JEPA）**： Yang立昆提到了他的联合嵌入预测架构(JEPA)，这个架构的核心理念是放弃像素级别的预测，而是让模型学习对世界运作的抽象表示，然后训练AI根据这些表示来预测未来的状态。

3. **科学的本质**： Yang立昆将这个过程称为科学的本质，通过寻找某种现象的良好版本，使模型在遇到不良状况时能进行规划和预测，从而回到良好的版本上。

4. **信息量估计**：为了稳定地训练联合嵌入预测架构（JEPA），Yang立昆提到了信息量估计，然后测量来自编码器的信息内容。

5. **Meta的开源哲学**： Yang立昆还提到，Meta认为开源人工智能不仅是好主意，而且对于文化多样性和民主的保存来说是必要的，而开源人工智能模型的可用性正是推动人工智能初创生态系统发展的原因之一。

这篇文章总结了Yang立昆在2023年的演讲内容，这些概念对了解当前人工智能研究方向有重要参考价值。